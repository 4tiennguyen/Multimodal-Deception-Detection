# Multimodal-Deception-Detection
Researchers have shown increasing interest in automatically detecting deceptive behavior, actions, and content in recent years. This growing focus is driven by the broad applications of deception detection, particularly in fields like criminology and cybersecurity. Our study explores text and audio data from natural language speeches to contribute to this research area. We evaluate traditional linguistic models, deep learning models, and advanced Large Language Models (LLMs) using Natural Language Processing (NLP) techniques to identify deception. Additionally, we apply various feature selection methods to assess the importance of linguistic features. Through comprehensive experimentation, we examine the performance of conventional and deep models on transcribed data and test deep models on audio data, creating a multimodal approach for lie detection. Our results show that the Bidirectional Long Short-Term Memory (BiLSTM) model is highly effective in processing text, while the ResNet50 model excels in analyzing audio data. By combining these models through late fusion, we develop a multimodal system that surpasses the performance of individual text and audio models.
